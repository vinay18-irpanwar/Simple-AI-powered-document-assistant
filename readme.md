# ğŸ“„ AI-Powered PDF Research Assistant

An intelligent **Retrieval-Augmented Generation (RAG)** web application built using **Streamlit, LangChain, Gemini, and FAISS**.

Upload any PDF document and ask questions â€” the AI answers strictly based on the document content.

---

## ğŸš€ Features

- ğŸ“‚ Upload any PDF document  
- ğŸ” Semantic search using FAISS  
- ğŸ§  Context-aware answers using Gemini (LLM)  
- ğŸ“‘ Smart document chunking  
- âš¡ Fast embeddings using sentence-transformers  
- ğŸ¨ Clean and interactive Streamlit UI  
- ğŸ” Secure API key management  

---

## ğŸ—ï¸ Tech Stack

| Component        | Technology |
|------------------|------------|
| Frontend         | Streamlit |
| LLM              | Gemini (Google Generative AI) |
| Framework        | LangChain |
| Embeddings       | sentence-transformers |
| Vector Database  | FAISS |
| PDF Loader       | PyMuPDF |

---

## ğŸ“‚ Project Structure


AI-PDF-Research-Assistant/
â”‚
â”œâ”€â”€ app.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env
â””â”€â”€ README.md


---

## ğŸ” Setup Instructions

### 1ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/yourusername/AI-PDF-Research-Assistant.git
cd AI-PDF-Research-Assistant
2ï¸âƒ£ Create Virtual Environment
python -m venv venv

Activate the environment:

Windows

.\venv\Scripts\activate

Mac/Linux

source venv/bin/activate
3ï¸âƒ£ Install Dependencies
pip install -r requirements.txt
4ï¸âƒ£ Add Gemini API Key

Create a .env file in the root directory:

GOOGLE_API_KEY=your_api_key_here
â–¶ï¸ Run the Application
streamlit run app.py

Then open:

http://localhost:8501
ğŸ§  How It Works (RAG Pipeline)

User uploads a PDF.

PDF text is extracted using PyMuPDF.

Text is split into smaller chunks.

Chunks are converted into embeddings.

FAISS stores embeddings for semantic search.

Relevant chunks are retrieved based on the query.

Gemini generates a response using retrieved context only.

ğŸ“Œ Example Questions

Summarize the document

What is the main objective?

Explain the methodology

Compare advantages and disadvantages

What conclusion is drawn?

ğŸ“¦ Requirements

streamlit

langchain

langchain-community

langchain-google-genai

faiss-cpu

pymupdf

sentence-transformers

python-dotenv

âš ï¸ Note

On first run, the embedding model (~90MB) will download automatically.
Subsequent runs will load instantly from cache.

ğŸ”® Future Improvements

Multi-PDF support

Conversational chat mode

Source citation display

Persistent vector storage

Deployment on Streamlit Cloud
